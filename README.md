# cuda-flash-attention

A simplified flash-attention implementation in CUDA. Uses tiling and online softmax.

## building the project

```bash
mkdir build
cd build
cmake ..
make

./flash_attention
```
